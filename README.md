# Lunar Lander Optimization with IOH

Project for Natural Computing @ Leiden University in WS 2025/26. 
Ready-to-run LunarLander optimization suite with multiple evolution strategies
and Differential Evolution variants, instrumented for IOH logging.

ðŸ“„ Read the report [here](https://github.com/JonasSaathoff/Lunar-Lander/blob/main/report.pdf)


## Overview
- Gym wrapper for LunarLander (`GymProblem`) supporting discrete/continuous control and wind/gravity presets.
- DE family (rand/1, rand/2, best/1, best/2, rand-to-best/2, current-to-best/1, adaptive, mixed-strategy) plus (1+1)-ES baselines.
- IOH-integrated runner to benchmark any subset of algorithms and presets.
- Smoke-test script for quick sanity checks.

## Project Structure
```
â”œâ”€â”€ problem.py                       # Gym wrapper used by all algorithms
â”œâ”€â”€ adapters.py                      # Stable call signatures for algorithms
â”œâ”€â”€ algorithms/
â”‚   â”œâ”€â”€ adaptive_differential_evolution.py
â”‚   â”œâ”€â”€ adaptive_mixed_de.py
â”‚   â”œâ”€â”€ differential_evolution.py
â”‚   â”œâ”€â”€ differential_evolution_rand2.py
â”‚   â”œâ”€â”€ differential_evolution_rand_to_best2.py
â”‚   â”œâ”€â”€ differential_evolution_best1.py
â”‚   â”œâ”€â”€ differential_evolution_best2.py
â”‚   â”œâ”€â”€ differential_evolution_current_to_best1.py
â”‚   â”œâ”€â”€ one_plus_one_es.py
â”‚   â”œâ”€â”€ one_plus_one_self_adaptive.py
â”‚   â”œâ”€â”€ one_plus_one_combo.py
â”‚   â””â”€â”€ random_search.py
â”œâ”€â”€ run_replicates_ioh_all.py        # IOH driver for batch runs
â”œâ”€â”€ run_sample.sh                    # One-line smoke test
â”œâ”€â”€ make_clean_submission.py         # Build clean submission zip
â””â”€â”€ requirements.txt
```

## Installation
```bash
python -m venv .venv
source .venv/bin/activate
pip install -r requirements.txt
```

## Quick Usage

### Smoke test (small IOH run)
```bash
./run_sample.sh
```
Runs `adaptive_mixed_de` for 1 replicate with a small budget and writes IOH logs to `sample_ioh/`.

### Custom IOH runs
```bash
python run_replicates_ioh_all.py \
  --presets nominal_continuous \
  --algos adaptive_mixed_de,de,best1 \
  --reps 5 \
  --budget 2000 \
  --out-root IOH_runs \
  --clean
```

Key flags:
- `--presets`: env presets (`nominal`, `nominal_continuous`, `wind_med`, `wind_high`, `gravity_low`, `gravity_high`, `turbulence_high`, `wind_and_gravity`).
- `--algos`: comma-separated names from `adapters.py`.
- `--budget`: iterations per algorithm (one env eval per iteration).
- `--reps`: replicate count; seeds start at 1000.
- `--out-root`: IOH output folder (zipped automatically at end).
- `--clean`: remove existing `out-root` before running.
- `--crossover`: for `adaptive_mixed_de`, choose `binomial` (default) or `exponential` crossover.

## GymProblem API (quick reference)

```python
GymProblem(
    continuous: bool = False,
    gravity: float = -10.0,
    enable_wind: bool = False,
    wind_power: float = 0.0,
    turbulence_power: float = 0.0,
)
```

- `.sample()`: draw from [-1, 1]^n where n = state_size Ã— n_outputs.
- `.play_episode(x, **env_kwargs)`: run a rollout; returns `(fitness, rewards)`.
- `__call__(x)`: shorthand for `play_episode(x, **simulation_params)`.
- `.show(x)`: render an episode (`render_mode="human"`).

### Minimal example
```python
from problem import GymProblem
import numpy as np

problem = GymProblem(continuous=False)
x = problem.sample()
f, rewards = problem(x)
print("Fitness:", f)
```
